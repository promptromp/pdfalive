{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>A Python library and CLI toolkit that brings PDF files alive with the power of LLMs.</p>"},{"location":"#highlights","title":"Highlights","text":"Feature Details Automatic TOC generation Generate clickable Table of Contents (PDF bookmarks) using LLM inference with intelligent batching for arbitrarily large documents Smart OCR detection Automatically detects scanned PDFs and performs OCR via Tesseract when needed Intelligent file renaming Batch rename files using natural language instructions with LLM-powered inference and confidence scoring Multi-provider LLM support Use any LLM provider via LangChain: OpenAI, Anthropic, local models via Ollama, and more TOC postprocessing Optional second LLM pass cross-references against printed TOC pages to fix typos, remove duplicates, and correct hierarchy TOML configuration Set persistent defaults for any CLI option via <code>pdfalive.toml</code> config files with per-command sections Built-in resilience Automatic retry logic with exponential backoff for handling API rate limits"},{"location":"#installation","title":"Installation","text":"<p>Tesseract is required for OCR functionality. On macOS:</p> <pre><code>brew install tesseract\n</code></pre> <p>Install pdfalive via pip:</p> <pre><code>pip install pdfalive\n</code></pre> <p>Or run directly without installation using uvx:</p> <pre><code>uvx pdfalive generate-toc input.pdf output.pdf\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Use <code>--help</code> on any command for detailed options:</p> <pre><code>pdfalive --help\npdfalive generate-toc --help\n</code></pre>"},{"location":"#generate-toc","title":"generate-toc","text":"<p>Generate a clickable Table of Contents using PDF bookmarks. The tool extracts font and text features from the PDF and uses an LLM to intelligently identify chapter and section headings.</p> <pre><code>pdfalive generate-toc input.pdf output.pdf\n\n# Or modify the file in place\npdfalive generate-toc --inplace input.pdf\n</code></pre> <p>Choosing an LLM:</p> <p>By default, pdfalive uses the latest OpenAI model. Use any LangChain-supported model:</p> <pre><code># Use Claude\npdfalive generate-toc --model-identifier 'claude-sonnet-4-5' input.pdf output.pdf\n\n# Use a local model via Ollama\npdfalive generate-toc --model-identifier 'ollama/llama3' input.pdf output.pdf\n</code></pre> <p>Set the appropriate API key for your provider (<code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, etc.).</p> <p>Scanned PDFs:</p> <p>OCR is enabled by default. Scanned documents without extractable text are automatically detected and processed:</p> <pre><code># Default: OCR text layer discarded after TOC generation (preserves file size)\npdfalive generate-toc scanned.pdf output.pdf\n\n# Include OCR text layer in output (makes PDF searchable)\npdfalive generate-toc --ocr-output scanned.pdf output.pdf\n\n# Disable automatic OCR entirely\npdfalive generate-toc --no-ocr input.pdf output.pdf\n</code></pre> <p>Postprocessing:</p> <p>For documents with a printed table of contents page, enable LLM postprocessing to refine results:</p> <pre><code>pdfalive generate-toc --postprocess input.pdf output.pdf\n</code></pre> <p>Postprocessing uses an additional LLM call to: - Remove duplicate entries and fix typos - Cross-reference against any printed TOC found in the document - Add missing entries and correct page numbers</p> <p>Other options:</p> Option Description <code>--inplace</code> Modify the input file in place instead of creating a new output file <code>--force</code> Overwrite existing TOC if the PDF already has bookmarks <code>--ocr-language</code> Set OCR language (default: <code>eng</code>). Use Tesseract language codes <code>--request-delay</code> Delay between LLM calls for rate limiting (default: 10s)"},{"location":"#extract-text","title":"extract-text","text":"<p>Extract text from scanned PDFs using OCR and save to a new PDF with an embedded text layer:</p> <pre><code>pdfalive extract-text input.pdf output.pdf\n\n# Or modify the file in place\npdfalive extract-text --inplace input.pdf\n</code></pre> <p>This creates a searchable/selectable PDF without generating a TOC.</p> <p>Options:</p> Option Description <code>--inplace</code> Modify the input file in place instead of creating a new output file <code>--force</code> Force OCR even if document already has text <code>--ocr-language</code> Set OCR language (default: <code>eng</code>) <code>--ocr-dpi</code> DPI resolution for OCR processing (default: 300)"},{"location":"#rename","title":"rename","text":"<p>Intelligently rename files using LLM inference. Analyzes filenames and applies renaming rules based on natural language instructions.</p> <pre><code>pdfalive rename -q \"Add 'REVIEWED_' prefix\" *.pdf\n</code></pre> <p>Custom naming formats:</p> <p>Specify exact formatting including special characters \u2014 the LLM respects brackets, parentheses, dashes, and other formatting:</p> <pre><code>pdfalive rename -q \"[Author Last Name] - Title (Year).pdf\" paper1.pdf paper2.pdf\n</code></pre> <p>Reading paths from a file:</p> <p>When dealing with many files or long filenames that exceed command-line limits, use the <code>-f</code>/<code>--input-file</code> option to read paths from a text file (one per line):</p> <pre><code># Generate a list of files to rename\nfind /path/to/docs -name \"*.pdf\" &gt; files.txt\n\n# Rename using the file list\npdfalive rename -q \"Standardize filenames\" -f files.txt\n</code></pre> <p>The input file supports comments (lines starting with <code>#</code>) and blank lines are ignored.</p> <p>Workflow:</p> <ol> <li>The tool analyzes each filename and generates rename suggestions</li> <li>A preview table shows original names, proposed names, confidence scores, and reasoning</li> <li>Confirm or cancel the operation (unless <code>-y</code> is used)</li> <li>Files are renamed in place</li> </ol> <p>Automatic confirmation:</p> <pre><code>pdfalive rename -q \"Add sequential numbering prefix\" -y *.pdf\n</code></pre> <p>Options:</p> Option Description <code>-f, --input-file</code> Read input file paths from a text file (one per line) <code>--model-identifier</code> Choose which LLM to use (default: <code>gpt-5.2</code>) <code>-y, --yes</code> Automatically apply renames without confirmation <code>--show-token-usage</code> Display token usage statistics (default: enabled)"},{"location":"#configuration","title":"Configuration","text":"<p>pdfalive supports TOML configuration files for setting default options. This is useful for frequently-used settings like the <code>--query</code> argument for rename.</p> <p>Config file locations (searched in order): 1. <code>pdfalive.toml</code> or <code>.pdfalive.toml</code> in the current directory 2. <code>pdfalive.toml</code> or <code>.pdfalive.toml</code> in your home directory 3. <code>~/.config/pdfalive/pdfalive.toml</code></p> <p>Example <code>pdfalive.toml</code>:</p> <pre><code># Global settings (shared across commands)\n[global]\nmodel-identifier = \"gpt-5.2\"\nshow-token-usage = true\n\n# Settings for generate-toc command\n[generate-toc]\nforce = false\nrequest-delay = 10.0\nocr = true\nocr-language = \"eng\"\nocr-dpi = 300\npostprocess = false\n\n# Settings for extract-text command\n[extract-text]\nocr-language = \"eng\"\nocr-dpi = 300\nforce = false\n\n# Settings for rename command\n[rename]\nquery = \"Rename to \\\"[Author Last Name] Book Title, Edition (Year).pdf\\\"\"\nyes = false\n</code></pre> <p>Using a specific config file:</p> <pre><code>pdfalive --config /path/to/config.toml rename document.pdf\n</code></pre> <p>Override hierarchy: 1. Code defaults (lowest priority) 2. Config file values 3. CLI arguments (highest priority)</p> <p>CLI arguments always override config file settings.</p>"},{"location":"#development","title":"Development","text":"<p>We use uv to manage the project:</p> <pre><code># Install dependencies\nuv sync\n\n# Install in editable mode\nuv pip install -e .\n</code></pre> <p>Code quality tools:</p> Tool Purpose ruff Formatting and linting mypy Static type checking pytest Unit testing pre-commit Git hooks for quality checks <pre><code># Run linting\nuv run ruff check .\nuv run ruff format .\n\n# Run type checking\nuv run mypy pdfalive\n\n# Run tests\nuv run pytest\n</code></pre>"},{"location":"#license","title":"License","text":"<p>pdfalive is distributed under the terms of the MIT License.</p>"},{"location":"hardcoded-constants-review/","title":"Hard-coded Constants in TOC Generation: Review and Alternatives","text":""},{"location":"hardcoded-constants-review/#overview","title":"Overview","text":"<p>The TOC generation pipeline in <code>pdfalive/processors/toc_generator.py</code> uses several hard-coded string patterns, dictionaries, and threshold constants. This document catalogs them, describes where they sit in the pipeline, and evaluates alternatives \u2014 particularly delegating more work to the LLM.</p>"},{"location":"hardcoded-constants-review/#constants-inventory","title":"Constants Inventory","text":""},{"location":"hardcoded-constants-review/#stringpattern-matching","title":"String/Pattern Matching","text":"Constant Type Purpose <code>_FRONT_MATTER_TITLES</code> <code>frozenset</code> of strings Skip known front matter titles (Contents, Preface, Introduction, Foreword, Acknowledgements, etc.) when detecting the printed-to-PDF page offset <code>_SECTION_NUMBER_PATTERN</code> Compiled regex Match section numbering prefixes: \"1.\", \"1.2\", \"Chapter N\", \"Section N\", \"Part N\", \"Appendix N\", Roman numerals (\"XIV.\"), letter-spaced \"C H A P T E R\" <code>_LETTERSPACED_PATTERN</code> Compiled regex Match ALL-CAPS letter-spaced text like \"P R E F A C E\" <code>_ROMAN_NUMERAL_RE</code> Regex sub-pattern Match Roman numerals I through XXXIX (used inside <code>_SECTION_NUMBER_PATTERN</code>)"},{"location":"hardcoded-constants-review/#numeric-thresholds","title":"Numeric Thresholds","text":"Constant Value Purpose <code>_HEADING_MIN_LENGTH</code> 3 Minimum text length for a heading candidate <code>_HEADING_MAX_LENGTH</code> 200 Maximum text length for a heading candidate <code>_HEADING_FONT_SIZE_RATIO</code> 1.15 Font must be &gt;= 1.15x body text size to be considered a heading"},{"location":"hardcoded-constants-review/#where-they-sit-in-the-pipeline","title":"Where They Sit in the Pipeline","text":""},{"location":"hardcoded-constants-review/#phase-0-feature-extraction-pre-llm","title":"Phase 0: Feature Extraction (pre-LLM)","text":"<p>Used by: <code>_is_heading_candidate()</code>, called from <code>_extract_features_sequential()</code> and <code>_extract_features_parallel()</code></p> <p>After extracting the first N blocks per page, remaining blocks are scanned for heading candidates. The constants decide which overflow spans are worth including as features sent to the LLM.</p> <p>Constants involved: - <code>_SECTION_NUMBER_PATTERN</code> \u2014 text-based heading detection - <code>_LETTERSPACED_PATTERN</code> \u2014 text-based heading detection - <code>_HEADING_MIN_LENGTH</code> / <code>_HEADING_MAX_LENGTH</code> \u2014 length bounds - <code>_HEADING_FONT_SIZE_RATIO</code> \u2014 font-size-based heading detection</p> <p>Key point: The LLM never sees spans that are filtered out here. This is a gate that determines what information reaches the LLM.</p>"},{"location":"hardcoded-constants-review/#phase-2-post-llm-correction-after-postprocessing","title":"Phase 2: Post-LLM Correction (after postprocessing)","text":"<p>Used by: <code>_detect_front_matter_offset()</code>, called from <code>_correct_postprocessed_page_numbers()</code></p> <p>After the postprocessor LLM refines the TOC, the correction code identifies the front matter offset by finding the first \"real\" chapter in the Phase 1 TOC. <code>_FRONT_MATTER_TITLES</code> determines which entries to skip.</p> <p>Constants involved: - <code>_FRONT_MATTER_TITLES</code> \u2014 title classification</p> <p>Key point: This runs after both LLM passes. It's a deterministic heuristic trying to fix what the LLM may have gotten wrong.</p>"},{"location":"hardcoded-constants-review/#brittleness-concerns","title":"Brittleness Concerns","text":""},{"location":"hardcoded-constants-review/#_front_matter_titles-high-brittleness","title":"<code>_FRONT_MATTER_TITLES</code> \u2014 High brittleness","text":"<ul> <li>English-only: Won't match \"Inhaltsverzeichnis\", \"Pr\u00e9face\", \"\u00cdndice\", \"Sommaire\", etc.</li> <li>Requires ongoing maintenance: We already had to add \"introduction\" and switch from exact matching to prefix matching because \"Acknowledgments for the English Edition\" didn't match. Every book with unusual front matter labels is a potential failure.</li> <li>Ambiguous entries: \"Introduction\" can be either front matter or the first real chapter depending on the book. Currently treated as front matter.</li> </ul>"},{"location":"hardcoded-constants-review/#_section_number_pattern-moderate-brittleness","title":"<code>_SECTION_NUMBER_PATTERN</code> \u2014 Moderate brittleness","text":"<ul> <li>English-centric named prefixes: \"Chapter\", \"Section\", \"Part\", \"Appendix\" won't match \"Cap\u00edtulo\", \"Chapitre\", \"Kapitel\", \"Abschnitt\", etc.</li> <li>Roman numerals are universal: The <code>_ROMAN_NUMERAL_RE</code> sub-pattern works across languages.</li> <li>Letter-spacing is universal: <code>_LETTERSPACED_PATTERN</code> works for any Latin-alphabet text.</li> </ul>"},{"location":"hardcoded-constants-review/#numeric-thresholds-low-brittleness","title":"Numeric thresholds \u2014 Low brittleness","text":"<ul> <li><code>_HEADING_FONT_SIZE_RATIO</code> (1.15x) is a reasonable universal heuristic \u2014 larger font means heading regardless of language.</li> <li><code>_HEADING_MIN/MAX_LENGTH</code> (3\u2013200) are generous bounds unlikely to cause issues.</li> </ul>"},{"location":"hardcoded-constants-review/#alternatives-delegating-to-the-llm","title":"Alternatives: Delegating to the LLM","text":""},{"location":"hardcoded-constants-review/#_front_matter_titles-strong-candidate-for-removal","title":"<code>_FRONT_MATTER_TITLES</code> \u2014 Strong candidate for removal","text":"<p>This is the most problematic constant and the most replaceable. Options:</p> <ol> <li> <p>Remove offset detection entirely. The \"prompt-first\" approach (telling the LLM to always output PDF page numbers with an explicit conversion formula) is already in place. If the LLM follows the prompt correctly, no downstream offset correction is needed. The correction code becomes a safety net, not the primary mechanism. We could simplify it to only restore matched entries' page numbers without trying to detect/apply offsets.</p> </li> <li> <p>Ask the LLM to identify the offset. Include Phase 1 TOC entries in the postprocessor prompt and ask the LLM to determine the front matter offset itself. The LLM can understand \"Contents\", \"Pr\u00e9face\", \"Einleitung\" etc. without a hard-coded list.</p> </li> <li> <p>Use the LLM to classify entries. Instead of a title list, ask the LLM in the postprocessor prompt: \"Which of these entries are front matter vs. main content?\" This is inherently multilingual.</p> </li> </ol> <p>Recommendation: Option 1 (simplify/remove) is the cleanest. The offset detection was added as a band-aid for the LLM outputting wrong page numbers. With clear prompts and the conversion formula, the LLM should handle this directly. The correction code should focus only on restoring matched entries' page numbers (which is language-neutral \u2014 it uses the Phase 1 page numbers, not title matching).</p>"},{"location":"hardcoded-constants-review/#_section_number_pattern-_letterspaced_pattern-partial-candidate","title":"<code>_SECTION_NUMBER_PATTERN</code> / <code>_LETTERSPACED_PATTERN</code> \u2014 Partial candidate","text":"<p>These are used in feature extraction to decide which spans to send to the LLM. The LLM can't replace a pre-LLM filter. Options:</p> <ol> <li> <p>Relax the filter. Send more spans to the LLM (increase <code>max_blocks_per_page</code> or reduce filtering strictness) and let the LLM decide what's a heading. Cost: more tokens per call.</p> </li> <li> <p>Keep font-based heuristics, drop text-based patterns. The font size ratio and bold detection are language-neutral and effective. The regex patterns add English-specific assumptions on top. We could keep <code>_HEADING_FONT_SIZE_RATIO</code> and bold detection as the only heading candidate criteria, dropping the regex patterns.</p> </li> <li> <p>Keep as-is. These patterns are a performance optimization (fewer tokens sent to the LLM). The LLM still makes the final heading decision \u2014 these just control which candidates it sees. Mis-classification here means a missed heading, but the LLM compensates from the blocks it does see.</p> </li> </ol> <p>Recommendation: Option 2 (keep font heuristics, drop text patterns) is a good balance. Font size and bold are universal signals. The regex patterns add marginal value at the cost of English-only assumptions.</p>"},{"location":"hardcoded-constants-review/#numeric-thresholds-keep-as-is","title":"Numeric thresholds \u2014 Keep as-is","text":"<p>These are language-neutral and unlikely to cause issues. No action needed.</p>"},{"location":"hardcoded-constants-review/#summary","title":"Summary","text":"Constant Brittleness i18n impact Recommendation <code>_FRONT_MATTER_TITLES</code> High Breaks for non-English Remove or delegate to LLM <code>_SECTION_NUMBER_PATTERN</code> Moderate Named prefixes are English-only Drop text patterns, keep font heuristics <code>_LETTERSPACED_PATTERN</code> Low Works for Latin alphabets Could drop (low marginal value) <code>_ROMAN_NUMERAL_RE</code> Low Universal Could drop (part of section pattern) <code>_HEADING_FONT_SIZE_RATIO</code> Low Universal Keep <code>_HEADING_MIN/MAX_LENGTH</code> Low Universal Keep"},{"location":"usage/","title":"Usage Guide: pdfalive","text":"<p><code>pdfalive</code> is a Python package with a command-line interface for enhancing PDF files using LLMs.</p>"},{"location":"usage/#installation","title":"Installation","text":"<p>Install via pip:</p> <pre><code>pip install pdfalive\n</code></pre> <p>Or run directly with uvx (no installation needed):</p> <pre><code>uvx pdfalive --help\n</code></pre>"},{"location":"usage/#commands","title":"Commands","text":""},{"location":"usage/#generate-toc","title":"generate-toc","text":"<p>Generate a clickable Table of Contents for any PDF. The tool analyzes font sizes, text patterns, and document structure to identify chapters and sections.</p> <p>Basic usage:</p> <pre><code>pdfalive generate-toc input.pdf output.pdf\n\n# Or modify the file in place\npdfalive generate-toc --inplace input.pdf\n</code></pre> <p>Using a different LLM:</p> <pre><code># Use Claude instead of the default OpenAI model\npdfalive generate-toc --model-identifier 'claude-sonnet-4-5' input.pdf output.pdf\n\n# Use a local model via Ollama\npdfalive generate-toc --model-identifier 'ollama/llama3' input.pdf output.pdf\n</code></pre> <p>Don't forget to set the appropriate API key environment variable for your provider (<code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, etc.).</p> <p>Working with scanned PDFs:</p> <p>OCR is enabled by default. Scanned documents without extractable text will be automatically detected and OCR will be performed to extract text before TOC generation.</p> <pre><code># Default behavior: OCR enabled, text layer discarded (preserves file size)\npdfalive generate-toc scanned.pdf output.pdf\n\n# Include OCR text layer in output (makes PDF searchable)\npdfalive generate-toc --ocr-output scanned.pdf output.pdf\n\n# Disable automatic OCR entirely\npdfalive generate-toc --no-ocr input.pdf output.pdf\n</code></pre> <p>OCR options:</p> <pre><code># Use a different language for OCR (default: English)\npdfalive generate-toc --ocr-language deu german_document.pdf output.pdf\n\n# Adjust OCR resolution (default: 300 DPI)\npdfalive generate-toc --ocr-dpi 150 input.pdf output.pdf\n</code></pre> <p>Postprocessing for improved quality:</p> <p>Enable LLM postprocessing to refine the generated TOC. This is especially useful for documents that have a printed table of contents page:</p> <pre><code># Enable postprocessing to clean up and improve the TOC\npdfalive generate-toc --postprocess input.pdf output.pdf\n</code></pre> <p>Postprocessing performs an additional LLM call that: - Removes duplicate entries and fixes typos - Cross-references against any printed TOC found in the first pages - Adds missing entries and corrects page numbers based on the printed TOC - Ensures consistent hierarchy levels</p> <p>Other options:</p> <pre><code># Modify file in place\npdfalive generate-toc --inplace input.pdf\n\n# Overwrite existing bookmarks\npdfalive generate-toc --force input.pdf output.pdf\n\n# Adjust rate limiting delay between LLM calls\npdfalive generate-toc --request-delay 5 input.pdf output.pdf\n</code></pre>"},{"location":"usage/#extract-text","title":"extract-text","text":"<p>Extract text from scanned PDFs using OCR, creating a searchable PDF with an embedded text layer.</p> <p>Basic usage:</p> <pre><code>pdfalive extract-text scanned.pdf searchable.pdf\n\n# Or modify the file in place\npdfalive extract-text --inplace scanned.pdf\n</code></pre> <p>Options:</p> <pre><code># Modify file in place\npdfalive extract-text --inplace input.pdf\n\n# Force OCR even if document already has text\npdfalive extract-text --force input.pdf output.pdf\n\n# Use a different language\npdfalive extract-text --ocr-language fra french_document.pdf output.pdf\n</code></pre>"},{"location":"usage/#rename","title":"rename","text":"<p>Intelligently rename PDF files using LLM-powered inference. The tool analyzes filenames and applies your renaming instructions.</p> <p>Basic usage:</p> <pre><code>pdfalive rename -q \"Add 'REVIEWED_' prefix\" *.pdf\n</code></pre> <p>Custom naming formats with special characters:</p> <pre><code># Rename to format: [Author Last Name] - Title (Year).pdf\npdfalive rename -q \"[Author Last Name] - Title (Year).pdf\" paper1.pdf paper2.pdf\n\n# Rename with curly braces: {Category}_Filename.pdf\npdfalive rename -q \"{Category}_Filename.pdf\" *.pdf\n</code></pre> <p>The LLM respects your exact formatting, including brackets, parentheses, dashes, and other special characters.</p> <p>Reading paths from a file:</p> <p>When dealing with many files or long filenames that exceed command-line limits, use the <code>-f</code>/<code>--input-file</code> option:</p> <pre><code># Generate a list of files to rename\nfind /path/to/docs -name \"*.pdf\" &gt; files.txt\n\n# Rename using the file list\npdfalive rename -q \"Standardize filenames\" -f files.txt\n</code></pre> <p>The input file should contain one path per line. Lines starting with <code>#</code> are treated as comments and blank lines are ignored.</p> <p>Options:</p> <pre><code># Use a different LLM\npdfalive rename -q \"Standardize filenames\" --model-identifier 'claude-sonnet-4-5' *.pdf\n\n# Skip confirmation prompt\npdfalive rename -q \"Add sequential numbering\" -y *.pdf\n\n# Read paths from a file\npdfalive rename -q \"Add prefix\" -f paths.txt\n</code></pre> <p>Workflow:</p> <ol> <li>The tool analyzes each filename and generates rename suggestions</li> <li>A preview table shows original names, proposed new names, confidence scores, and reasoning</li> <li>You confirm or cancel the operation (unless <code>-y</code> is used)</li> <li>Files are renamed in place (same directory)</li> </ol>"},{"location":"usage/#configuration","title":"Configuration","text":"<p>pdfalive supports TOML configuration files for setting default CLI options. This is especially useful for frequently-used settings like the <code>--query</code> argument for rename.</p> <p>Config file locations (searched in order): 1. <code>pdfalive.toml</code> or <code>.pdfalive.toml</code> in the current directory 2. <code>pdfalive.toml</code> or <code>.pdfalive.toml</code> in your home directory 3. <code>~/.config/pdfalive/pdfalive.toml</code></p> <p>Example configuration file:</p> <pre><code># pdfalive.toml\n\n# Global settings (shared across commands)\n[global]\nmodel-identifier = \"gpt-5.2\"\nshow-token-usage = true\n\n# Settings for generate-toc command\n[generate-toc]\nforce = false\nrequest-delay = 10.0\nocr = true\nocr-language = \"eng\"\nocr-dpi = 300\npostprocess = false\n\n# Settings for extract-text command\n[extract-text]\nocr-language = \"eng\"\nocr-dpi = 300\nforce = false\n\n# Settings for rename command\n[rename]\nquery = \"Rename to \\\"[Author Last Name] Book Title, Edition (Year).pdf\\\"\"\nyes = false\n</code></pre> <p>Using a specific config file:</p> <pre><code>pdfalive --config /path/to/config.toml rename document.pdf\n</code></pre> <p>Override hierarchy: 1. Code defaults (lowest priority) 2. Config file values 3. CLI arguments (highest priority)</p> <p>CLI arguments always override config file settings.</p>"},{"location":"usage/#tips","title":"Tips","text":"<ul> <li>For large documents, the tool automatically batches LLM requests to stay within context limits</li> <li>Rate limiting is built-in with automatic retry logic for API errors</li> <li>Use <code>--help</code> on any command for a full list of options</li> </ul>"}]}